#!/bin/bash

function print_usage_and_exit {
	/bin/echo "usage: ${progname} <job_prefix> -a <account> -c <coordinates>" >&2
	/bin/echo "           -p <topology> -x <mdp_file> [ -d ] [ -e <email_address> ]" >&2
	/bin/echo "           [ -f <first_stage> ] [ -k <num_cores> ] [ -m <mem_per_cpu> ]" >&2
	/bin/echo "           [ -n <num_stages> ] [ -r ] [ -t <walltime_per_stage> ]" >&2
	/bin/echo "           [ -y ]" >&2
	exit $1
}

function print_help_and_exit {

	/bin/cat << ENDHELP
      ${progname}
      
      This script will take a specified job name, as well as coordinate
      (.gro), topology (.top) and configuration (.mdp) files, and submit
      a series of GROMACS molecular dynamics simulations.
      
      Usage: ${progname} <job_prefix> -a <account> -c <init_coordinates>
                   -p <topology> [ -d ] [ -e <email_address> ]
                   [ -f <first_stage> ] [ -k <num_cores> ]
                   [ -m <mem_per_cpu> ] [ -n <num_stages> ]
                   [ -r ] [ -t <walltime_per_stage> ] [ -x <mdp_file> ]
                   [ -y ]
             ${progname} -h
     
      -a <account>, --account=<account>

            Tell the script what account code (project code) you would like to
            use.
      
      -c <init_coordinates>, --coordinates=<init_coordinates>
            
            Tell the script what GROMACS format coordinate file you would like
            to use as the initial coordinates.
      
      -d, --data-fabric

            Transfer the results of each stage to the NeSI Data Fabric upon
            that stage's successful completion.
      
      -e, --email=<email_address>
      
            The email address to which to send job notifications. If not
            provided, no job notifications will be sent by the scheduler.

      -f, --first-stage=<num>

            The first stage of this simulation to run. This is primarily
            intended for restarting simulations that have crashed or otherwise
            failed. It can be used in conjunction with -r, but doesn't have
            to be (for instance, if you wish to resume from the very start
            of the specified stage).

      -h, --help

            Print this help and exit.
      
      -k, --cores=<num_cores>

            Number of cores to request for each step. Must be a multiple
            of 16. The default is 16.
      
      -m, --mem-per-cpu=<memory>
      
            Tell the script how much memory to allocate to each CPU core
            (default 4 GB). If no units are given, MB will be assumed.

      -n <num_stages>, --num-stages=<num_stages>

            Tell the script how many stages of MD simulation you would like
            to run. The default is 1.
      
      -p <topology>, --topology=<topology>

            Tell the script what GROMACS format topology file you would like
            to use.

      -t <walltime>, --walltime=<walltime>

            Tell the script how long you want each stage to be run for (the
            maximum wall time). The default is 24 hours.
      
      -x <mdp_file>, --mdp-file=<mdp_file>
      
            Tell the script which MDP file to use as a basis for simulation
            configuration. An actual MDP file will be generated for each
            step, which will be a processed version of this input.
      
      -y, --hybrid

            Use hybrid (OpenMP + MPI) parallelism. Default is no (i.e., MPI
            parallelism only).

ENDHELP
}

function read_mdp_file {
	while read line
	do
		if [[ "${line}" =~ ^[[:space:]]*gen_vel[[:space:]]*= ]]
		then
			# Negated spaces need one bracket, not two
			first_gen_vel=$(echo ${line} | /bin/sed -e "s/^[[:space:]]*gen_vel[[:space:]]*=[[:space:]]*\([^;[:space:]]\+\).*/\1/")
		elif [[ "${line}" =~ ^[[:space:]]*continuation[[:space:]]*= ]]
		then
			first_continuation=$(echo ${line} | /bin/sed -e "s/^[[:space:]]*continuation[[:space:]]*=[[:space:]]*\([^;[:space:]]\+\).*/\1/")
		elif [[ "${line}" =~ ^[[:space:]]*nsteps[[:space:]]*= ]]
		then
			total_num_steps=$(echo ${line} | /bin/sed -e "s/^[[:space:]]*nsteps[[:space:]]*=[[:space:]]\([[:digit:]]\+\).*/\1/")
			steps_per_stage=$((total_num_steps/numstages))
		elif [[ "${line}" =~ ^[[:space:]]*dt*[[:space:]]*= ]]
		then
			timestep=$(echo ${line} | /bin/sed -e "s/^[[:space:]]*dt[[:space:]]*=[[:space:]]\([^;[:space:]]\+\).*/\1/")
			# Now we will have to deal with floating points, more's the pity.
			time_offset_per_stage=$(echo "${steps_per_stage}*${timestep}" | bc)
		fi
	done < ${mdp_file}
}

function write_mdp_file {

	# This function writes the Gromacs simulation configuration (*.mdp) file.
	#
	# Positional parameters:
	#
	# $1 = stage number (1, 2, 3, etc.)
	# $2 = stage name (stage001, stage002, stage003, etc.)

	local gen_vel="no"
	local continuation="yes"
	local mysteps="${steps_per_stage}"
	if [ "$1" -eq 1 ]
	then
		gen_vel=${first_gen_vel}
		continuation=${first_continuation}
	fi
	if [ "$1" -eq "${numstages}" ]
	then
		let "mysteps = $steps_per_stage + ($total_num_steps % $numstages)"
	fi

	tinit=$(echo "${time_offset_per_stage}*($1-1)" | bc)

	local found_tinit_line=false
	while read line
	do
		if [[ "${line}" =~ ^[[:space:]]*tinit[[:space:]]*= ]]
		then
			found_tinit_line=true
		fi
		/bin/echo $line | \
		/bin/sed -e "s/^\([[:space:]]*gen_vel\)[[:space:]]*=[[:space:]]*[^;]*/\1 = ${gen_vel} /" | \
		/bin/sed -e "s/^\([[:space:]]*continuation\)[[:space:]]*=[[:space:]]*[^;]*/\1 = ${continuation} /" | \
		/bin/sed -e "s/^\([[:space:]]*nsteps\)[[:space:]]*=[[:space:]]*[^;]*/\1 = ${mysteps} /" | \
		/bin/sed -e "s/^\([[:space:]]*tinit\)[[:space:]]*=[[:space:]]*[^;]*/\1 = ${tinit} /"
	done < ${mdp_file_full} > "$2.mdp"

	# Print a tinit line if we don't have one already
	if ! ${found_tinit_line}
	then
		echo "tinit = ${tinit}" >> "$2.mdp"
	fi
}

function write_shell_script_component {
	# This function writes the shell script for each job - the part that
	# will actually be executed.
	# 
	# Positional parameters:
	# First argument = stage name (stage001, stage002, etc.)
	# Second argument = name of previous stage (stage000, stage001, etc.)
	# Third argument = stage number (1, 2, 3, etc.)
	# 
	# If this is the first stage, then stuff will be written to the transfer
	# script so that when the transfer script is executed the first thing it
	# will do is set up a new iRODS certificate. Because this only needs to be
	# done once per running of the transfer script, it need only happen for
	# the first MD stage.
	# 
	# If this is the last stage, copy the output files from it as well when it
	# finishes.
	# 
	# If this is any stage (including the first and the last), copy the output
	# files from the *previous* stage. In all stages, grompp and mdrun_mpi will
	# also be run.
	
	grompp_args="-f $1.mdp -c $2.gro -p ${topology_base} -o $1.tpr"
	mdrun_args="-pin on -noconfout -cpt 15 -cpo $1.cpt -s $1.tpr -o $1.trr -c $1.gro -e $1.edr -g $1.log -v"
	# Only do this for the first simulation stage
	if ${restart_stage}
	then
		mdrun_args="${mdrun_args} -cpi $1.cpt"
		restart_stage=false
	fi
	if ${hybrid}
	then
		mdrun_args="-ntomp 16 ${mdrun_args}"
	fi

	/bin/cat << EOSS

module load GROMACS/4.6.5-intel-2015a-hybrid

thisdir=\$(pwd -P)

echo "Copying input data to \${CHK_DIR} ..." && \\
cp $2.gro ${topology_base} $1.mdp \${CHK_DIR} && \\
cd \${CHK_DIR} && \\
srun grompp ${grompp_args} && \\
echo "Note: Simulation logs will be written to $1.log" && \\
srun mdrun_mpi ${mdrun_args} && \\
cp -arv $1.tpr $1.trr $1.gro $1.edr $1.log \${thisdir} && \\
cd \${thisdir} && \\
rm -rv \${CHK_DIR}/* && \\
EOSS
	if ${data_fabric}
	then
		# On the first stage, set up an iRODS directory
		# on the Data Fabric
		if [ $3 -eq 1 ]
		then
			cat << EOSS
cat << EOTFR >> ${tfrcmd}
#!/bin/sh

echo ''
echo 'You will now be prompted for your iRODS password. By authenticating, you will'
echo 'generate an iRODS certificate that will last for several months. This will be'
echo 'used to copy data to and from the Data Fabric.'
echo ''
iinit
echo ''
echo 'Please specify an iRODS (Data Fabric) destination directory.'
echo 'Your home directory on the Data Fabric will be used as a prefix. The'
echo 'destination directory will have a "Production" directory created within'
echo 'it.'
echo ''
echo -n 'Directory: '
read df_dest_dir_parent
df_dest_dir=\${df_dest_dir_parent}/Production
imkdir -p \${df_dest_dir}
echo ''
EOTFR

chmod +x ${tfrcmd}
EOSS
		# On all but the first stage, queue a copy of the preceding
		# stage's output to the Data Fabric
		else
			cat << EOSS
cat << EOTFR >> ${tfrcmd}
${iput_command} $2.mdp \${df_dest_dir}
${iput_command} $2.tpr \${df_dest_dir}
${iput_command} $2.trr \${df_dest_dir}
${iput_command} $2.edr \${df_dest_dir}
${iput_command} $2.log \${df_dest_dir}
${iput_command} $2.out \${df_dest_dir}
${iput_command} $2.err \${df_dest_dir}
EOTFR
EOSS
		fi
		# On the last stage, queue a copy of its own output to
		# the Data Fabric
		if [ $3 -eq $numstages ]
		then
			/bin/cat << EOSS

cat << EOTFR >> ${tfrcmd}
${iput_command} ${topology_full} \${df_dest_dir}
${iput_command} $1.mdp \${df_dest_dir}
${iput_command} $1.gro \${df_dest_dir}
${iput_command} $1.tpr \${df_dest_dir}
${iput_command} $1.trr \${df_dest_dir}
${iput_command} $1.edr \${df_dest_dir}
${iput_command} $1.log \${df_dest_dir}
${iput_command} ${jobprefix}_$1.out \${df_dest_dir}
${iput_command} ${jobprefix}_$1.err \${df_dest_dir}
EOTFR
EOSS
		fi
		# On any stage (even the first), queue a copy of the
		# preceding stage's coordinate file to the Data Fabric
		cat << EOSS

cat << EOTFR >> ${tfrcmd}
${iput_command} $2.gro \${df_dest_dir}
EOTFR
EOSS
	else
		/bin/cat << EOSS
true
EOSS
	fi
}

function write_slurm_component {

	# Write the header to the Slurm job command file. Properties set here
	# will, as far as possible, be applied to all jobs.
	# 
	# Important ones to be aware of:
	# - you may only run on Sandy Bridge nodes
	#
	# Positional parameters:
	# $1 = current stage name (stage001, stage002, etc.)
	# $2 = previous job ID

	/bin/cat << EOSLURM
#!/bin/bash

#SBATCH --job-name        ${jobprefix}_$1
#SBATCH --account         ${account}
#SBATCH --time            ${walltime}
#SBATCH --ntasks          ${tasks}
#SBATCH --nodes           ${nodes}
#SBATCH --ntasks-per-node $((tasks/nodes))
#SBATCH --cpus-per-task   ${cpus_per_task}
#SBATCH --mem-per-cpu     ${mem_per_cpu}
#SBATCH --constraint      sb 
#SBATCH --output          $1.out
#SBATCH --error           $1.err
EOSLURM
	if [ -n "${email_address}" ]
	then
		/bin/echo "#SBATCH --mail-type       ALL"
		/bin/echo "#SBATCH --mail-user       ${email_address}"
	fi
	if [ "$1" != "stage001" ]
	then
		/bin/echo "#SBATCH --dependency      afterok:$2"
	fi
}

#######################
##                   ##
##  THE MAIN SCRIPT  ##
##                   ##
#######################

# Ensure that we don't have any uninitialised variables in this script
set -u

# Set the program name for later use
progname=$(basename $0)

# Set some default values
account=""
coordinates=""
cores=16
currdir=$(pwd -P)
data_fabric=false
email_address=""
first_continuation="no"
first_gen_vel="yes"
first_stage=1
hybrid=false
jobprefix=""
mdp_file=""
mem_per_cpu="4G"
numstages=1
restart_stage=false
steps_per_stage=1
time_offset_per_stage=0
topology=""
total_num_steps=0
walltime="24:00:00"

ARGS=$(getopt -o a:c:de:f:hk:m:n:p:rt:x:y -l "account:,coordinates:,data-fabric,email:,first-stage:,help,cores:,mem-per-cpu:,num-stages:,topology:,restart,walltime:,mdp-file:,hybrid" -n "${progname}" -- "$@");

#Bad arguments
if [ $? -ne 0 ]
then
	exit 1
fi

eval set -- "$ARGS";

while true
do
	case "$1" in
	-a|--account)
		shift
		if [ -n "$1" ]
		then
			account=$1
			shift
		fi
		;;
	-c|--coordinates)
		shift
		if [ -n "$1" ]
		then
			coordinates=$1
			shift
		fi
		;;
	-d|--data-fabric)
		shift
		data_fabric=true
		;;
	-e|--email)
		shift
		if [ -n "$1" ]
		then
			email_address=$1
			shift
		fi
		;;
	-f|--first-stage)
		shift
		if [ -n "$1" ]
		then
			first_stage=$1
			shift
		fi
		;;
	-h|--help)
		shift
		print_help_and_exit
		;;
	-k|--cores)
		shift
		if [ -n "$1" ]
		then
			cores=$1
			shift
		fi
		;;
	-m|--mem-per-cpu)
		shift
		if [ -n "$1" ]
		then
			mem_per_cpu=$1
			shift
		fi
		;;
	-n|--num-stages)
		shift
		if [ -n "$1" ]
		then
			numstages=$1
			shift
		fi
		;;
	-p|--topology)
		shift
		if [ -n "$1" ]
		then
			topology=$1
			shift
		fi
		;;
	-r|--restart)
		shift
		restart_stage=true
		;;
	-t|--walltime)
		shift
		if [ -n "$1" ]
		then
			walltime=$1
			shift
		fi
		;;
	-x|--mdp-file)
		shift
		if [ -n "$1" ]
		then
			mdp_file=$1
			shift
		fi
		;;
	-y|--hybrid)
		shift
		hybrid=true
		;;
	--)
		shift
		break
		;;
	esac
done

# Die if the number of arguments is wrong
if [ $# -gt 1 -o -z "${account}" -o -z "${coordinates}" -o -z "${topology}" -o -z "${mdp_file}" ]
then
	print_usage_and_exit 1
elif [ $# -eq 1 ]
then
	jobprefix=$1
fi

# If the number of stages is not a positive integer, die.
if [ ${numstages} -le 0 ]
then
	/bin/echo "${progname}: number of stages should be a positive integer" >&2
	exit 1
fi

# If the first stage is not a positive integer <= numstages, die.
if [ ${first_stage} -gt ${numstages} ] || [ ${first_stage} -le 0 ]
then
	/bin/echo "${progname}: first stage should be a positive integer <= ${numstages}" >&2
	exit 1
fi

# If the walltime is not of an acceptable format, die.
if [[ ! "${walltime}" =~ ([0-9]+-)?[0-9]+:[0-9][0-9]:[0-9][0-9] ]]
then
	/bin/echo "${progname}: wall time should be of the form hhh:mm:ss or ddd-hhh:mm:ss" >&2
	exit 1
fi

if (( ${cores} % 16 == 0 ))
then
	nodes=$((cores/16))
	if ${hybrid}
	then
		tasks=$((cores/16))
		cpus_per_task=16
	else
		tasks=${cores}
		cpus_per_task=1
	fi
else
	/bin/echo "${progname}: number of cores should be a multiple of 16" >&2
	exit 1
fi

if [[ ! "${mem_per_cpu}" =~ [0-9]+[KMGT]?B? ]]
then
	/bin/echo "${progname}: memory per CPU should be of the form #, #<B|K|M|G|T>" >&2
	/bin/echo "or #<KB|MB|GB|TB>" >&2
	exit 1
fi

if [[ -n "${email_address}" && ! "${email_address}" =~ .+@.+ ]]
then
	/bin/echo "${progname}: ${email_address}: not a valid email address" >&2
	exit 1
fi

if [ -z "${jobprefix}" ]
then
	/bin/echo "No job name prefix has been specified."
elif [ ${#jobprefix} -gt 12 ]
then
	/bin/echo "Job prefix \"${jobprefix}\" is too long."
	jobprefix=""
fi

if [ -z "${jobprefix}" ]
then
	prompt=$(/bin/basename "${currdir}" | /bin/cut -c 1-8)
	while [ -z "${jobprefix}" ]
	do
		/bin/echo -n "Please enter a job name prefix: [${prompt}] "
		read answer
		if [ -z "${answer}" ]
		then
			jobprefix="${prompt}"
		elif [ ${#answer} -gt 12 ]
		then
			/bin/echo "Prefix too long. Please choose another, at most 12 characters."
		elif [[ "${answer}" =~ [[:space:]] ]]
		then
			/bin/echo "Spaces are not permitted. Please choose a different prefix."
		else
			jobprefix="${answer}"
		fi
	done	
fi

# Command to copy a file to the Data Fabric using iRODS software
iput_command="iput -N 4 -K -P -V"

# Set the full path, the job name, and make a directory
# called "production" in the working directory.
# This means any existing "production" directory should be checked
# to make sure nothing important will be used or overwritten inappropriately.
workdir="${currdir}/production"
tfrcmd="${workdir}/transfer_script"
/bin/rm -f "${tfrcmd}"

for inputfile in ${coordinates} ${topology} ${mdp_file}
do
	if [ ! -e "${inputfile}" ]
	then
		/bin/echo "${progname}: ${inputfile}: no such file or directory" >&2
		exit 1
	elif [ ! -f "${inputfile}" ]
	then
		/bin/echo "${progname}: ${inputfile}: not a file" >&2
		exit 1
	elif [ ! -r "${inputfile}" ]
	then
		/bin/echo "${progname}: ${inputfile}: permission denied" >&2
		exit 1
	fi
done

if [ -d "${workdir}" ]
then
	# Back up any existing directory with the same name
	# as the proposed working directory. If a directory
	# with the same name as the backup directory also
	# exists, prompt.
	/bin/mv -i "${workdir}" "${workdir}.bak"
fi
read_mdp_file
coordinates_full=$(/bin/readlink -f "${coordinates}")
topology_full=$(/bin/readlink -f "${topology}")
topology_base=$(/bin/basename ${topology})
mdp_file_full=$(/bin/readlink -f "${mdp_file}")
/bin/mkdir -p "${workdir}"
/bin/ln -s "${coordinates_full}" "${workdir}/stage000.gro"
/bin/ln -s "${topology_full}" "${workdir}/${topology_base}"

# Ensure that jobs are submitted from within the specified working directory
# (this has important implications for where output will be copied back to)
cd "${workdir}"

prevjobid=0
prevstageid=$((first_stage-1))
prevstagename=$(/usr/bin/printf "stage%03d\n" ${prevstageid})
for i in $(/usr/bin/seq ${first_stage} ${numstages})
do
	stagename=$(/usr/bin/printf "stage%03d\n" $i)
	jobfile="${workdir}/${stagename}.sl"
	write_slurm_component ${stagename} ${prevjobid} > ${jobfile}
	write_shell_script_component ${stagename} ${prevstagename} $i >> ${jobfile}
	write_mdp_file $i ${stagename}

	# Set this job ID for use in subsequent dependencies
	submission_output=$(sbatch ${jobfile})
	if [[ "${submission_output}" =~ ^Submitted[[:space:]]batch[[:space:]]job[[:space:]] ]]
	then
		prevjobid=$(/bin/echo "${submission_output}" | /bin/sed -e 's/Submitted batch job //')
	else
		/bin/echo "${progname}: submission of stage ${i} of ${numstages} failed -- stopping" >&2
		exit 1
	fi
	prevstagename="${stagename}"
done

# Return to the starting directory, just because it's good practice
cd "${currdir}"
